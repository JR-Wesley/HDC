{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using {} device\".format(device))\n",
    "\n",
    "DIMENSIONS = 1024  # number of hypervector dimensions\n",
    "BATCH_SIZE = 12  # for GPUs with enough memory we can process multiple images at ones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据集\n",
    "\n",
    "下载好 ISOLET 数据集。\n",
    "\n",
    "通过 `torch.utils.data.Dataset` 构建数据集类，实现必要的方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Programming Note\n",
    "在Python中，`from typing import ...` 是一种导入语句，用于从 `typing` 模块导入特定的类型注解工具。`typing` 模块提供了用于支持Python类型提示（Type Hints）的工具，这些工具可以帮助开发者为函数参数和返回值指定预期的类型，从而提高代码的可读性和可维护性。\n",
    "\n",
    "以下是你提到的每个导入项的简要说明：\n",
    "\n",
    "1. **`Callable`**：\n",
    "   - `Callable` 是一个类型注解，用于注解一个可调用对象，即任何可以像函数一样被调用的对象。例如，函数、方法、类实例等。\n",
    "   - 示例：`def process_data(func: Callable[[int, str], float]) -> None:` 表示 `process_data` 函数接受一个参数 `func`，它是一个接受一个整数和一个字符串并返回一个浮点数的可调用对象。\n",
    "\n",
    "2. **`Optional`**：\n",
    "   - `Optional` 是一个类型注解，用于注解一个可能为 `None` 的值。\n",
    "   - 示例：`def greet(name: Optional[str]) -> None:` 表示 `greet` 函数接受一个参数 `name`，它可以是一个字符串或者 `None`。\n",
    "\n",
    "3. **`Tuple`**：\n",
    "   - `Tuple` 是一个泛型类型注解，用于注解一个元组，其元素类型是固定的。\n",
    "   - 示例：`def get_coordinates() -> Tuple[int, int]:` 表示 `get_coordinates` 函数返回一个包含两个整数的元组。\n",
    "\n",
    "4. **`List`**：\n",
    "   - `List` 是一个泛型类型注解，用于注解一个列表，其元素类型是固定的。\n",
    "   - 示例：`def get_numbers() -> List[int]:` 表示 `get_numbers` 函数返回一个包含整数的列表。\n",
    "\n",
    "这些类型注解工具使得代码更加清晰，因为它们明确了函数参数和返回值的预期类型。此外，它们还可以被静态类型检查器（如 `mypy`）用来检查类型错误，从而在代码运行之前发现潜在的问题。\n",
    "\n",
    "以下是如何使用这些类型注解的一个示例：\n",
    "\n",
    "```python\n",
    "from typing import Callable, Optional, Tuple, List\n",
    "\n",
    "# 定义一个函数，接受一个整数和一个字符串，返回一个浮点数\n",
    "def process_data(func: Callable[[int, str], float]) -> None:\n",
    "    result = func(10, \"hello\")\n",
    "    print(result)\n",
    "\n",
    "# 定义一个函数，接受一个可能为None的字符串参数\n",
    "def greet(name: Optional[str]) -> None:\n",
    "    if name is not None:\n",
    "        print(f\"Hello, {name}!\")\n",
    "    else:\n",
    "        print(\"Hello, stranger!\")\n",
    "\n",
    "# 定义一个函数，返回一个整数元组\n",
    "def get_coordinates() -> Tuple[int, int]:\n",
    "    return (1, 2)\n",
    "\n",
    "# 定义一个函数，返回一个整数列表\n",
    "def get_numbers() -> List[int]:\n",
    "    return [1, 2, 3]\n",
    "```\n",
    "\n",
    "在这个示例中，我们使用了 `Callable`、`Optional`、`Tuple` 和 `List` 来为函数参数和返回值添加类型注解。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "from typing import Callable, Optional, Tuple, List\n",
    "\n",
    "class ISOLET(Dataset):\n",
    "    \"\"\"\n",
    "    Description\n",
    "    ===\n",
    "    `ISOLET <https://archive.ics.uci.edu/ml/datasets/isolet>`_ dataset.\n",
    "    The data file has been downloaded and extracted, existing in the directory of `root`.\n",
    "\n",
    "    Args:\n",
    "    root (string): Root directory of dataset where ``isolet1+2+3+4.data``\n",
    "        and  ``isolet5.data`` exist.\n",
    "    train (bool, optional): If True, creates dataset from ``isolet1+2+3+4.data``,\n",
    "        otherwise from ``isolet5.data``.\n",
    "\n",
    "    transform (callable, optional): A function/transform that takes in an torch.FloatTensor\n",
    "        and returns a transformed version.\n",
    "    target_transform (callable, optional): A function/transform that takes in the\n",
    "        target and transforms it.\n",
    "\n",
    "    \"\"\"\n",
    "    classes: List[str] = [\n",
    "        \"A\",\n",
    "        \"B\",\n",
    "        \"C\",\n",
    "        \"D\",\n",
    "        \"E\",\n",
    "        \"F\",\n",
    "        \"G\",\n",
    "        \"H\",\n",
    "        \"I\",\n",
    "        \"J\",\n",
    "        \"K\",\n",
    "        \"L\",\n",
    "        \"M\",\n",
    "        \"N\",\n",
    "        \"O\",\n",
    "        \"P\",\n",
    "        \"Q\",\n",
    "        \"R\",\n",
    "        \"S\",\n",
    "        \"T\",\n",
    "        \"U\",\n",
    "        \"V\",\n",
    "        \"W\",\n",
    "        \"X\",\n",
    "        \"Y\",\n",
    "        \"Z\",        \n",
    "    ]\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            root: str,\n",
    "            train: bool = True,\n",
    "            transform: Optional[Callable] = None,\n",
    "            target_transform: Optional[Callable] = None\n",
    "            ):\n",
    "        super().__init__()\n",
    "        root = os.path.join(root, \"isolet\")\n",
    "        root = os.path.expanduser(root)\n",
    "        self.root = root\n",
    "        os.makedirs(self.root, exist_ok=True)\n",
    "\n",
    "        self.train = train\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "        if not self._check_integrity():\n",
    "            raise RuntimeError(\n",
    "                \"Dataset not found or corrupted.\"\n",
    "            )\n",
    "        \n",
    "        self._load_data()\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"\n",
    "        Function\n",
    "        ===\n",
    "        Subclasses could optionally overwrite :meth:`__len__`.\n",
    "\n",
    "        Return\n",
    "        ---\n",
    "        the number of the samples in the dataset\n",
    "        \"\"\"\n",
    "        return self.data.size(0)\n",
    "    \n",
    "    def __getitem__(self, index) -> Tuple[torch.FloatTensor, torch.LongTensor]:\n",
    "        \"\"\"\n",
    "        Function\n",
    "        ===\n",
    "        All subclasses should overwrite :meth:`__getitem__`, supporting fetching a\n",
    "        data sample for a given key. \n",
    "\n",
    "        Parameters\n",
    "        ---\n",
    "            index (int): Index\n",
    "\n",
    "        Returns:\n",
    "            Tuple: (sample, Target) where target is the index of tghe target class\n",
    "        \"\"\"\n",
    "        sample = self.data[index]\n",
    "        label = self.targets[index]\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "\n",
    "        return sample, label\n",
    "\n",
    "\n",
    "    def _check_integrity(self) -> bool:\n",
    "        \"\"\"\n",
    "        Function\n",
    "        ===\n",
    "        Unzip the dataset file.\n",
    "        Check if `root`  is a legal directory and if the root directory contains the required file\n",
    "        \"\"\"\n",
    "        if not os.path.isdir(self.root):\n",
    "            return False\n",
    "        \n",
    "        train_file = os.path.join(self.root, \"isolet1+2+3+4.data\")\n",
    "        test_file = os.path.join(self.root, \"isolet5.data\")\n",
    "\n",
    "        has_train_file = os.path.isfile(train_file)\n",
    "        has_test_file = os.path.isfile(test_file)\n",
    "\n",
    "        if has_train_file and has_test_file:\n",
    "            return True\n",
    "        \n",
    "        # TODO: Add more specific checks like an MD5 ckecksum\n",
    "\n",
    "        return False\n",
    "\n",
    "    def _load_data(self):\n",
    "        \"\"\"\n",
    "        Function\n",
    "        ===\n",
    "        Load ISOLET dataset from `path` where ``isolet1+2+3+4.data`` and ``isolet5.data`` exist\n",
    "        Metadata is stored in `data` and `targets`.\n",
    "\n",
    "        Parameter\n",
    "        ---\n",
    "        train (bool, optional): If True, creates dataset from ``isolet1+2+3+4.data``,\n",
    "        otherwise from ``isolet5.data``.\n",
    "\n",
    "        \"\"\"\n",
    "        data_file = \"isolet1+2+3+4.data\" if self.train else \"isolet5.data\"\n",
    "        data = pd.read_csv(os.path.join(self.root, data_file), header=None)\n",
    "        self.data = torch.tensor(data.values[:, :-1], dtype=torch.float)\n",
    "        self.targets = torch.tensor(data.values[:, -1], dtype=torch.long) - 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_ds = ISOLET(\"../../data\", train=True)\n",
    "train_ld = torch.utils.data.DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "test_ds = ISOLET(\"../../data\", train=False)\n",
    "test_ld = torch.utils.data.DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "num_features = train_ds[0][0].size(-1)\n",
    "num_classes = len(train_ds.classes)\n",
    "\n",
    "classifiers = [\n",
    "    \"Vanilla\",\n",
    "    \"AdaptHD\",\n",
    "    \"OnlineHD\",\n",
    "    \"NeuralHD\",\n",
    "    \"DistHD\",\n",
    "    \"CompHD\",\n",
    "    \"SparseHD\",\n",
    "    \"QuantHD\",\n",
    "    \"LeHDC\",\n",
    "    \"IntRVFL\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std, mean = torch.std_mean(train_ds.data, dim=0, keepdim=False)\n",
    "\n",
    "\n",
    "def transform(sample):\n",
    "    return (sample - mean) / std\n",
    "\n",
    "\n",
    "train_ds.transform = transform\n",
    "test_ds.transform = transform\n",
    "\n",
    "params = {\n",
    "    \"Vanilla\": {},\n",
    "    \"AdaptHD\": {\n",
    "        \"epochs\": 10,\n",
    "    },\n",
    "    \"OnlineHD\": {\n",
    "        \"epochs\": 10,\n",
    "    },\n",
    "    \"NeuralHD\": {\n",
    "        \"epochs\": 10,\n",
    "        \"regen_freq\": 5,\n",
    "    },\n",
    "    \"DistHD\": {\n",
    "        \"epochs\": 10,\n",
    "        \"regen_freq\": 5,\n",
    "    },\n",
    "    \"CompHD\": {},\n",
    "    \"SparseHD\": {\n",
    "        \"epochs\": 10,\n",
    "    },\n",
    "    \"QuantHD\": {\n",
    "        \"epochs\": 10,\n",
    "    },\n",
    "    \"LeHDC\": {\n",
    "        \"epochs\": 10,\n",
    "    },\n",
    "    \"IntRVFL\": {},\n",
    "}\n",
    "\n",
    "for classifier in classifiers:\n",
    "    print()\n",
    "    print(classifier)\n",
    "\n",
    "    model_cls = getattr(torchhd.classifiers, classifier)\n",
    "    model: torchhd.classifiers.Classifier = model_cls(\n",
    "        num_features, DIMENSIONS, num_classes, device=device, **params[classifier]\n",
    "    )\n",
    "\n",
    "    model.fit(train_ld)\n",
    "    accuracy = model.accuracy(test_ld)\n",
    "    print(f\"Testing accuracy of {(accuracy * 100):.3f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hdc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
