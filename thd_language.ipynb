{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/210032 [00:00<?, ?it/s]/tmp/ipykernel_1124050/982165224.py:65: DeprecationWarning: torchhd.hard_quantize is deprecated, consider using torchhd.normalize instead.\n",
      "  return torchhd.hard_quantize(sample_hv)\n",
      "Training: 100%|██████████| 210032/210032 [04:20<00:00, 806.67it/s] \n",
      "Testing:   0%|          | 0/210032 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Encountered different devices in metric calculation (see stacktrace for details). This could be due to the metric class not being on the same device as input. Instead of `metric=MulticlassAccuracy(...)` try to do `metric=MulticlassAccuracy(...).to(device)` where device corresponds to the device of the input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/sw/miniconda3/envs/hdc/lib/python3.12/site-packages/torchmetrics/metric.py:482\u001b[0m, in \u001b[0;36mMetric._wrap_update.<locals>.wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 482\u001b[0m     update(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    483\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/sw/miniconda3/envs/hdc/lib/python3.12/site-packages/torchmetrics/classification/stat_scores.py:343\u001b[0m, in \u001b[0;36mMulticlassStatScores.update\u001b[0;34m(self, preds, target)\u001b[0m\n\u001b[1;32m    342\u001b[0m preds, target \u001b[38;5;241m=\u001b[39m _multiclass_stat_scores_format(preds, target, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtop_k)\n\u001b[0;32m--> 343\u001b[0m tp, fp, tn, fn \u001b[38;5;241m=\u001b[39m _multiclass_stat_scores_update(\n\u001b[1;32m    344\u001b[0m     preds, target, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_classes, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtop_k, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maverage, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmultidim_average, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mignore_index\n\u001b[1;32m    345\u001b[0m )\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_state(tp, fp, tn, fn)\n",
      "File \u001b[0;32m~/sw/miniconda3/envs/hdc/lib/python3.12/site-packages/torchmetrics/functional/classification/stat_scores.py:401\u001b[0m, in \u001b[0;36m_multiclass_stat_scores_update\u001b[0;34m(preds, target, num_classes, top_k, average, multidim_average, ignore_index)\u001b[0m\n\u001b[1;32m    400\u001b[0m     target \u001b[38;5;241m=\u001b[39m target[idx]\n\u001b[0;32m--> 401\u001b[0m tp \u001b[38;5;241m=\u001b[39m (preds \u001b[38;5;241m==\u001b[39m target)\u001b[38;5;241m.\u001b[39msum()\n\u001b[1;32m    402\u001b[0m fp \u001b[38;5;241m=\u001b[39m (preds \u001b[38;5;241m!=\u001b[39m target)\u001b[38;5;241m.\u001b[39msum()\n",
      "File \u001b[0;32m~/sw/miniconda3/envs/hdc/lib/python3.12/site-packages/torch/_tensor.py:1512\u001b[0m, in \u001b[0;36mTensor.__torch_function__\u001b[0;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _C\u001b[38;5;241m.\u001b[39mDisableTorchFunctionSubclass():\n\u001b[0;32m-> 1512\u001b[0m     ret \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1513\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m get_default_nowrap_functions():\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 94\u001b[0m\n\u001b[1;32m     92\u001b[0m         samples_hv \u001b[38;5;241m=\u001b[39m encode(samples)\n\u001b[1;32m     93\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m model(samples_hv, dot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 94\u001b[0m         accuracy\u001b[38;5;241m.\u001b[39mupdate(outputs\u001b[38;5;241m.\u001b[39mcpu(), labels)\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTesting accuracy of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(accuracy\u001b[38;5;241m.\u001b[39mcompute()\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m100\u001b[39m)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/sw/miniconda3/envs/hdc/lib/python3.12/site-packages/torchmetrics/metric.py:485\u001b[0m, in \u001b[0;36mMetric._wrap_update.<locals>.wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    484\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected all tensors to be on\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(err):\n\u001b[0;32m--> 485\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    486\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered different devices in metric calculation (see stacktrace for details).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    487\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m This could be due to the metric class not being on the same device as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    488\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Instead of `metric=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m(...)` try to do\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    489\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `metric=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m(...).to(device)` where\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    490\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m device corresponds to the device of the input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    491\u001b[0m             ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    492\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_on_cpu:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Encountered different devices in metric calculation (see stacktrace for details). This could be due to the metric class not being on the same device as input. Instead of `metric=MulticlassAccuracy(...)` try to do `metric=MulticlassAccuracy(...).to(device)` where device corresponds to the device of the input."
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "\n",
    "# Note: this example requires the torchmetrics library: https://torchmetrics.readthedocs.io\n",
    "import torchmetrics\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torchhd\n",
    "from torchhd import embeddings\n",
    "from torchhd.models import Centroid\n",
    "from torchhd.datasets import EuropeanLanguages as Languages\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using {} device\".format(device))\n",
    "\n",
    "DIMENSIONS = 10000\n",
    "BATCH_SIZE = 1  # for GPUs with enough memory we can process multiple images at ones\n",
    "# cap maximum sample size to 128 characters (including spaces)\n",
    "MAX_INPUT_SIZE = 128\n",
    "PADDING_IDX = 0\n",
    "\n",
    "ASCII_A = ord(\"a\")\n",
    "ASCII_Z = ord(\"z\")\n",
    "ASCII_SPACE = ord(\" \")\n",
    "NUM_TOKENS = ASCII_Z - ASCII_A + 3  # a through z plus space and padding\n",
    "\n",
    "\n",
    "def char2int(char: str) -> int:\n",
    "    \"\"\"Map a character to its integer identifier\"\"\"\n",
    "    ascii_index = ord(char)\n",
    "\n",
    "    if ascii_index == ASCII_SPACE:\n",
    "        # Remap the space character to come after \"z\"\n",
    "        return ASCII_Z - ASCII_A + 1\n",
    "\n",
    "    return ascii_index - ASCII_A\n",
    "\n",
    "\n",
    "def transform(x: str) -> torch.Tensor:\n",
    "    char_ids = x[:MAX_INPUT_SIZE]\n",
    "    char_ids = [char2int(char) + 1 for char in char_ids.lower()]\n",
    "\n",
    "    if len(char_ids) < MAX_INPUT_SIZE:\n",
    "        char_ids += [PADDING_IDX] * (MAX_INPUT_SIZE - len(char_ids))\n",
    "\n",
    "    return torch.tensor(char_ids, dtype=torch.long)\n",
    "\n",
    "train_ds = Languages(\"../../data\", train=True, transform=transform, download=False)\n",
    "train_ld = data.DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "test_ds = Languages(\"../../data\", train=False, transform=transform, download=False)\n",
    "test_ld = data.DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, out_features, size):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.symbol = embeddings.Random(size, out_features, padding_idx=PADDING_IDX)\n",
    "\n",
    "    def forward(self, x):\n",
    "        symbols = self.symbol(x)\n",
    "        sample_hv = torchhd.ngrams(symbols, n=3)\n",
    "        return torchhd.hard_quantize(sample_hv)\n",
    "\n",
    "\n",
    "encode = Encoder(DIMENSIONS, NUM_TOKENS)\n",
    "encode = encode.to(device)\n",
    "\n",
    "num_classes = len(train_ds.classes)\n",
    "model = Centroid(DIMENSIONS, num_classes)\n",
    "model = model.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for samples, labels in tqdm(train_ld, desc=\"Training\"):\n",
    "        samples = samples.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        samples_hv = encode(samples)\n",
    "        model.add(samples_hv, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:   0%|          | 0/210032 [00:00<?, ?it/s]/tmp/ipykernel_1124050/982165224.py:65: DeprecationWarning: torchhd.hard_quantize is deprecated, consider using torchhd.normalize instead.\n",
      "  return torchhd.hard_quantize(sample_hv)\n",
      "Testing:  29%|██▉       | 61939/210032 [02:31<06:01, 409.84it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m samples \u001b[38;5;241m=\u001b[39m samples\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      8\u001b[0m labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 10\u001b[0m samples_hv \u001b[38;5;241m=\u001b[39m encode(samples)\n\u001b[1;32m     11\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(samples_hv, dot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     12\u001b[0m accuracy\u001b[38;5;241m.\u001b[39mupdate(outputs, labels)\n",
      "File \u001b[0;32m~/sw/miniconda3/envs/hdc/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/sw/miniconda3/envs/hdc/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[1], line 65\u001b[0m, in \u001b[0;36mEncoder.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     63\u001b[0m symbols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msymbol(x)\n\u001b[1;32m     64\u001b[0m sample_hv \u001b[38;5;241m=\u001b[39m torchhd\u001b[38;5;241m.\u001b[39mngrams(symbols, n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torchhd\u001b[38;5;241m.\u001b[39mhard_quantize(sample_hv)\n",
      "File \u001b[0;32m~/sw/miniconda3/envs/hdc/lib/python3.12/site-packages/torchhd/functional.py:903\u001b[0m, in \u001b[0;36mhard_quantize\u001b[0;34m(input)\u001b[0m\n\u001b[1;32m    895\u001b[0m warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    896\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorchhd.hard_quantize is deprecated, consider using torchhd.normalize instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    897\u001b[0m     \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m,\n\u001b[1;32m    898\u001b[0m     stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m    899\u001b[0m )\n\u001b[1;32m    901\u001b[0m \u001b[38;5;66;03m# Make sure that the output tensor has the same dtype and device\u001b[39;00m\n\u001b[1;32m    902\u001b[0m \u001b[38;5;66;03m# as the input tensor.\u001b[39;00m\n\u001b[0;32m--> 903\u001b[0m positive \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;241m1.0\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdtype, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    904\u001b[0m negative \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1.0\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdtype, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    906\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mwhere(\u001b[38;5;28minput\u001b[39m \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, positive, negative)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "accuracy = torchmetrics.Accuracy(\"multiclass\", num_classes=num_classes).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.normalize()\n",
    "\n",
    "    for samples, labels in tqdm(train_ld, desc=\"Testing\"):\n",
    "        samples = samples.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        samples_hv = encode(samples)\n",
    "        outputs = model(samples_hv, dot=True).to(device)\n",
    "        accuracy.update(outputs, labels)\n",
    "\n",
    "print(f\"Testing accuracy of {(accuracy.compute().item() * 100):.3f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy of 95.407%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Testing accuracy of {(accuracy.compute().item() * 100):.3f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hdc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
